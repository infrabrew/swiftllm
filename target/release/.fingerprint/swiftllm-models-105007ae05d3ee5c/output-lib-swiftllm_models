{"$message_type":"diagnostic","message":"unused imports: `AttentionConfig`, `Attention`, `GatedMlp`, and `MlpConfig`","code":{"code":"unused_imports","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":139,"byte_end":148,"line_start":7,"line_end":7,"column_start":5,"column_end":14,"is_primary":true,"text":[{"text":"    Attention, AttentionConfig, Embedding, GatedMlp, LMHead, Linear, MlpConfig, RMSNorm,","highlight_start":5,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":150,"byte_end":165,"line_start":7,"line_end":7,"column_start":16,"column_end":31,"is_primary":true,"text":[{"text":"    Attention, AttentionConfig, Embedding, GatedMlp, LMHead, Linear, MlpConfig, RMSNorm,","highlight_start":16,"highlight_end":31}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":178,"byte_end":186,"line_start":7,"line_end":7,"column_start":44,"column_end":52,"is_primary":true,"text":[{"text":"    Attention, AttentionConfig, Embedding, GatedMlp, LMHead, Linear, MlpConfig, RMSNorm,","highlight_start":44,"highlight_end":52}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":204,"byte_end":213,"line_start":7,"line_end":7,"column_start":70,"column_end":79,"is_primary":true,"text":[{"text":"    Attention, AttentionConfig, Embedding, GatedMlp, LMHead, Linear, MlpConfig, RMSNorm,","highlight_start":70,"highlight_end":79}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`#[warn(unused_imports)]` (part of `#[warn(unused)]`) on by default","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"remove the unused imports","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":139,"byte_end":167,"line_start":7,"line_end":7,"column_start":5,"column_end":33,"is_primary":true,"text":[{"text":"    Attention, AttentionConfig, Embedding, GatedMlp, LMHead, Linear, MlpConfig, RMSNorm,","highlight_start":5,"highlight_end":33}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":176,"byte_end":186,"line_start":7,"line_end":7,"column_start":42,"column_end":52,"is_primary":true,"text":[{"text":"    Attention, AttentionConfig, Embedding, GatedMlp, LMHead, Linear, MlpConfig, RMSNorm,","highlight_start":42,"highlight_end":52}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":202,"byte_end":213,"line_start":7,"line_end":7,"column_start":68,"column_end":79,"is_primary":true,"text":[{"text":"    Attention, AttentionConfig, Embedding, GatedMlp, LMHead, Linear, MlpConfig, RMSNorm,","highlight_start":68,"highlight_end":79}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused imports: `AttentionConfig`, `Attention`, `GatedMlp`, and `MlpConfig`\u001b[0m\n \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/llama.rs:7:5\n  \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m7\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Attention, AttentionConfig, Embedding, GatedMlp, LMHead, Linear, MlpConfig, RMSNorm,\n  \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^\u001b[0m  \u001b[1m\u001b[33m^^^^^^^^^^^^^^^\u001b[0m             \u001b[1m\u001b[33m^^^^^^^^\u001b[0m                  \u001b[1m\u001b[33m^^^^^^^^^\u001b[0m\n  \u001b[1m\u001b[94m|\u001b[0m\n  \u001b[1m\u001b[94m= \u001b[0m\u001b[1mnote\u001b[0m: `#[warn(unused_imports)]` (part of `#[warn(unused)]`) on by default\n\n"}
{"$message_type":"diagnostic","message":"unused import: `swiftllm_core::config::DataType`","code":{"code":"unused_imports","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":255,"byte_end":286,"line_start":9,"line_end":9,"column_start":5,"column_end":36,"is_primary":true,"text":[{"text":"use swiftllm_core::config::DataType;","highlight_start":5,"highlight_end":36}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"remove the whole `use` item","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":251,"byte_end":288,"line_start":9,"line_end":10,"column_start":1,"column_end":1,"is_primary":true,"text":[{"text":"use swiftllm_core::config::DataType;","highlight_start":1,"highlight_end":37},{"text":"use swiftllm_core::error::{Error, Result};","highlight_start":1,"highlight_end":1}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused import: `swiftllm_core::config::DataType`\u001b[0m\n \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/attention.rs:9:5\n  \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m9\u001b[0m \u001b[1m\u001b[94m|\u001b[0m use swiftllm_core::config::DataType;\n  \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused import: `Error`","code":{"code":"unused_imports","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":315,"byte_end":320,"line_start":10,"line_end":10,"column_start":28,"column_end":33,"is_primary":true,"text":[{"text":"use swiftllm_core::error::{Error, Result};","highlight_start":28,"highlight_end":33}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"remove the unused import","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":315,"byte_end":322,"line_start":10,"line_end":10,"column_start":28,"column_end":35,"is_primary":true,"text":[{"text":"use swiftllm_core::error::{Error, Result};","highlight_start":28,"highlight_end":35}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":314,"byte_end":315,"line_start":10,"line_end":10,"column_start":27,"column_end":28,"is_primary":true,"text":[{"text":"use swiftllm_core::error::{Error, Result};","highlight_start":27,"highlight_end":28}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":328,"byte_end":329,"line_start":10,"line_end":10,"column_start":41,"column_end":42,"is_primary":true,"text":[{"text":"use swiftllm_core::error::{Error, Result};","highlight_start":41,"highlight_end":42}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused import: `Error`\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/attention.rs:10:28\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m10\u001b[0m \u001b[1m\u001b[94m|\u001b[0m use swiftllm_core::error::{Error, Result};\n   \u001b[1m\u001b[94m|\u001b[0m                            \u001b[1m\u001b[33m^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused import: `Device`","code":{"code":"unused_imports","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":424,"byte_end":430,"line_start":12,"line_end":12,"column_start":29,"column_end":35,"is_primary":true,"text":[{"text":"use swiftllm_core::tensor::{Device, Tensor};","highlight_start":29,"highlight_end":35}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"remove the unused import","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":424,"byte_end":432,"line_start":12,"line_end":12,"column_start":29,"column_end":37,"is_primary":true,"text":[{"text":"use swiftllm_core::tensor::{Device, Tensor};","highlight_start":29,"highlight_end":37}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":423,"byte_end":424,"line_start":12,"line_end":12,"column_start":28,"column_end":29,"is_primary":true,"text":[{"text":"use swiftllm_core::tensor::{Device, Tensor};","highlight_start":28,"highlight_end":29}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":438,"byte_end":439,"line_start":12,"line_end":12,"column_start":43,"column_end":44,"is_primary":true,"text":[{"text":"use swiftllm_core::tensor::{Device, Tensor};","highlight_start":43,"highlight_end":44}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused import: `Device`\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/attention.rs:12:29\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m12\u001b[0m \u001b[1m\u001b[94m|\u001b[0m use swiftllm_core::tensor::{Device, Tensor};\n   \u001b[1m\u001b[94m|\u001b[0m                             \u001b[1m\u001b[33m^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused import: `swiftllm_core::config::DataType`","code":{"code":"unused_imports","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/mod.rs","byte_start":422,"byte_end":453,"line_start":16,"line_end":16,"column_start":5,"column_end":36,"is_primary":true,"text":[{"text":"use swiftllm_core::config::DataType;","highlight_start":5,"highlight_end":36}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"remove the whole `use` item","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/layers/mod.rs","byte_start":418,"byte_end":455,"line_start":16,"line_end":17,"column_start":1,"column_end":1,"is_primary":true,"text":[{"text":"use swiftllm_core::config::DataType;","highlight_start":1,"highlight_end":37},{"text":"use swiftllm_core::error::Result;","highlight_start":1,"highlight_end":1}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused import: `swiftllm_core::config::DataType`\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/mod.rs:16:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m16\u001b[0m \u001b[1m\u001b[94m|\u001b[0m use swiftllm_core::config::DataType;\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused import: `SeekFrom`","code":{"code":"unused_imports","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":218,"byte_end":226,"line_start":9,"line_end":9,"column_start":38,"column_end":46,"is_primary":true,"text":[{"text":"use std::io::{BufReader, Read, Seek, SeekFrom};","highlight_start":38,"highlight_end":46}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"remove the unused import","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":216,"byte_end":226,"line_start":9,"line_end":9,"column_start":36,"column_end":46,"is_primary":true,"text":[{"text":"use std::io::{BufReader, Read, Seek, SeekFrom};","highlight_start":36,"highlight_end":46}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused import: `SeekFrom`\u001b[0m\n \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:9:38\n  \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m9\u001b[0m \u001b[1m\u001b[94m|\u001b[0m use std::io::{BufReader, Read, Seek, SeekFrom};\n  \u001b[1m\u001b[94m|\u001b[0m                                      \u001b[1m\u001b[33m^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused import: `Device`","code":{"code":"unused_imports","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/safetensors.rs","byte_start":335,"byte_end":341,"line_start":13,"line_end":13,"column_start":29,"column_end":35,"is_primary":true,"text":[{"text":"use swiftllm_core::tensor::{Device, Tensor};","highlight_start":29,"highlight_end":35}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"remove the unused import","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/loaders/safetensors.rs","byte_start":335,"byte_end":343,"line_start":13,"line_end":13,"column_start":29,"column_end":37,"is_primary":true,"text":[{"text":"use swiftllm_core::tensor::{Device, Tensor};","highlight_start":29,"highlight_end":37}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"crates/swiftllm-models/src/loaders/safetensors.rs","byte_start":334,"byte_end":335,"line_start":13,"line_end":13,"column_start":28,"column_end":29,"is_primary":true,"text":[{"text":"use swiftllm_core::tensor::{Device, Tensor};","highlight_start":28,"highlight_end":29}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"crates/swiftllm-models/src/loaders/safetensors.rs","byte_start":349,"byte_end":350,"line_start":13,"line_end":13,"column_start":43,"column_end":44,"is_primary":true,"text":[{"text":"use swiftllm_core::tensor::{Device, Tensor};","highlight_start":43,"highlight_end":44}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused import: `Device`\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/safetensors.rs:13:29\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m13\u001b[0m \u001b[1m\u001b[94m|\u001b[0m use swiftllm_core::tensor::{Device, Tensor};\n   \u001b[1m\u001b[94m|\u001b[0m                             \u001b[1m\u001b[33m^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused import: `Error`","code":{"code":"unused_imports","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/lib.rs","byte_start":359,"byte_end":364,"line_start":14,"line_end":14,"column_start":28,"column_end":33,"is_primary":true,"text":[{"text":"use swiftllm_core::error::{Error, Result};","highlight_start":28,"highlight_end":33}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"remove the unused import","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/lib.rs","byte_start":359,"byte_end":366,"line_start":14,"line_end":14,"column_start":28,"column_end":35,"is_primary":true,"text":[{"text":"use swiftllm_core::error::{Error, Result};","highlight_start":28,"highlight_end":35}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"crates/swiftllm-models/src/lib.rs","byte_start":358,"byte_end":359,"line_start":14,"line_end":14,"column_start":27,"column_end":28,"is_primary":true,"text":[{"text":"use swiftllm_core::error::{Error, Result};","highlight_start":27,"highlight_end":28}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"crates/swiftllm-models/src/lib.rs","byte_start":372,"byte_end":373,"line_start":14,"line_end":14,"column_start":41,"column_end":42,"is_primary":true,"text":[{"text":"use swiftllm_core::error::{Error, Result};","highlight_start":41,"highlight_end":42}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused import: `Error`\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/lib.rs:14:28\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m14\u001b[0m \u001b[1m\u001b[94m|\u001b[0m use swiftllm_core::error::{Error, Result};\n   \u001b[1m\u001b[94m|\u001b[0m                            \u001b[1m\u001b[33m^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"a method with this name may be added to the standard library in the future","code":{"code":"unstable_name_collisions","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":6150,"byte_end":6153,"line_start":269,"line_end":269,"column_start":53,"column_end":56,"is_primary":true,"text":[{"text":"    0.5 * x * (1.0 + (x / std::f32::consts::SQRT_2).erf())","highlight_start":53,"highlight_end":56}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"once this associated item is added to the standard library, the ambiguity may cause an error or change in behavior!","code":null,"level":"warning","spans":[],"children":[],"rendered":null},{"message":"for more information, see issue #48919 <https://github.com/rust-lang/rust/issues/48919>","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"call with fully qualified syntax `Erf::erf(...)` to keep using the current method","code":null,"level":"help","spans":[],"children":[],"rendered":null},{"message":"`#[warn(unstable_name_collisions)]` (part of `#[warn(future_incompatible)]`) on by default","code":null,"level":"note","spans":[],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: a method with this name may be added to the standard library in the future\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/mlp.rs:269:53\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m269\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     0.5 * x * (1.0 + (x / std::f32::consts::SQRT_2).erf())\n    \u001b[1m\u001b[94m|\u001b[0m                                                     \u001b[1m\u001b[33m^^^\u001b[0m\n    \u001b[1m\u001b[94m|\u001b[0m\n    \u001b[1m\u001b[94m= \u001b[0m\u001b[1mwarning\u001b[0m: once this associated item is added to the standard library, the ambiguity may cause an error or change in behavior!\n    \u001b[1m\u001b[94m= \u001b[0m\u001b[1mnote\u001b[0m: for more information, see issue #48919 <https://github.com/rust-lang/rust/issues/48919>\n    \u001b[1m\u001b[94m= \u001b[0m\u001b[1mhelp\u001b[0m: call with fully qualified syntax `Erf::erf(...)` to keep using the current method\n    \u001b[1m\u001b[94m= \u001b[0m\u001b[1mnote\u001b[0m: `#[warn(unstable_name_collisions)]` (part of `#[warn(future_incompatible)]`) on by default\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `residual`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":5174,"byte_end":5182,"line_start":194,"line_end":194,"column_start":13,"column_end":21,"is_primary":true,"text":[{"text":"        let residual = hidden_states;","highlight_start":13,"highlight_end":21}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`#[warn(unused_variables)]` (part of `#[warn(unused)]`) on by default","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":5174,"byte_end":5182,"line_start":194,"line_end":194,"column_start":13,"column_end":21,"is_primary":true,"text":[{"text":"        let residual = hidden_states;","highlight_start":13,"highlight_end":21}],"label":null,"suggested_replacement":"_residual","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `residual`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/llama.rs:194:13\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m194\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         let residual = hidden_states;\n    \u001b[1m\u001b[94m|\u001b[0m             \u001b[1m\u001b[33m^^^^^^^^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_residual`\u001b[0m\n    \u001b[1m\u001b[94m|\u001b[0m\n    \u001b[1m\u001b[94m= \u001b[0m\u001b[1mnote\u001b[0m: `#[warn(unused_variables)]` (part of `#[warn(unused)]`) on by default\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `residual`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":5506,"byte_end":5514,"line_start":200,"line_end":200,"column_start":13,"column_end":21,"is_primary":true,"text":[{"text":"        let residual = &hidden_states;","highlight_start":13,"highlight_end":21}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":5506,"byte_end":5514,"line_start":200,"line_end":200,"column_start":13,"column_end":21,"is_primary":true,"text":[{"text":"        let residual = &hidden_states;","highlight_start":13,"highlight_end":21}],"label":null,"suggested_replacement":"_residual","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `residual`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/llama.rs:200:13\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m200\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         let residual = &hidden_states;\n    \u001b[1m\u001b[94m|\u001b[0m             \u001b[1m\u001b[33m^^^^^^^^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_residual`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `cache_metadata`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":7983,"byte_end":7997,"line_start":296,"line_end":296,"column_start":9,"column_end":23,"is_primary":true,"text":[{"text":"        cache_metadata: &BatchedCacheMetadata,","highlight_start":9,"highlight_end":23}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":7983,"byte_end":7997,"line_start":296,"line_end":296,"column_start":9,"column_end":23,"is_primary":true,"text":[{"text":"        cache_metadata: &BatchedCacheMetadata,","highlight_start":9,"highlight_end":23}],"label":null,"suggested_replacement":"_cache_metadata","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `cache_metadata`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/llama.rs:296:9\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m296\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         cache_metadata: &BatchedCacheMetadata,\n    \u001b[1m\u001b[94m|\u001b[0m         \u001b[1m\u001b[33m^^^^^^^^^^^^^^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_cache_metadata`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `is_prefill`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":8030,"byte_end":8040,"line_start":297,"line_end":297,"column_start":9,"column_end":19,"is_primary":true,"text":[{"text":"        is_prefill: bool,","highlight_start":9,"highlight_end":19}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":8030,"byte_end":8040,"line_start":297,"line_end":297,"column_start":9,"column_end":19,"is_primary":true,"text":[{"text":"        is_prefill: bool,","highlight_start":9,"highlight_end":19}],"label":null,"suggested_replacement":"_is_prefill","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `is_prefill`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/llama.rs:297:9\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m297\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         is_prefill: bool,\n    \u001b[1m\u001b[94m|\u001b[0m         \u001b[1m\u001b[33m^^^^^^^^^^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_is_prefill`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `v`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":8222,"byte_end":8223,"line_start":302,"line_end":302,"column_start":13,"column_end":14,"is_primary":true,"text":[{"text":"        let v = self.v_proj.forward(hidden_states)?;","highlight_start":13,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":8222,"byte_end":8223,"line_start":302,"line_end":302,"column_start":13,"column_end":14,"is_primary":true,"text":[{"text":"        let v = self.v_proj.forward(hidden_states)?;","highlight_start":13,"highlight_end":14}],"label":null,"suggested_replacement":"_v","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `v`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/llama.rs:302:13\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m302\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         let v = self.v_proj.forward(hidden_states)?;\n    \u001b[1m\u001b[94m|\u001b[0m             \u001b[1m\u001b[33m^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_v`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `k`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":8318,"byte_end":8319,"line_start":305,"line_end":305,"column_start":17,"column_end":18,"is_primary":true,"text":[{"text":"        let (q, k) = self.rotary_emb.apply(&q, &k, positions)?;","highlight_start":17,"highlight_end":18}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":8318,"byte_end":8319,"line_start":305,"line_end":305,"column_start":17,"column_end":18,"is_primary":true,"text":[{"text":"        let (q, k) = self.rotary_emb.apply(&q, &k, positions)?;","highlight_start":17,"highlight_end":18}],"label":null,"suggested_replacement":"_k","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `k`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/llama.rs:305:17\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m305\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         let (q, k) = self.rotary_emb.apply(&q, &k, positions)?;\n    \u001b[1m\u001b[94m|\u001b[0m                 \u001b[1m\u001b[33m^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_k`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `up`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":9886,"byte_end":9888,"line_start":360,"line_end":360,"column_start":13,"column_end":15,"is_primary":true,"text":[{"text":"        let up = self.up_proj.forward(hidden_states)?;","highlight_start":13,"highlight_end":15}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":9886,"byte_end":9888,"line_start":360,"line_end":360,"column_start":13,"column_end":15,"is_primary":true,"text":[{"text":"        let up = self.up_proj.forward(hidden_states)?;","highlight_start":13,"highlight_end":15}],"label":null,"suggested_replacement":"_up","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `up`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/llama.rs:360:13\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m360\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         let up = self.up_proj.forward(hidden_states)?;\n    \u001b[1m\u001b[94m|\u001b[0m             \u001b[1m\u001b[33m^^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_up`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `cache_metadata`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":6827,"byte_end":6841,"line_start":241,"line_end":241,"column_start":9,"column_end":23,"is_primary":true,"text":[{"text":"        cache_metadata: &BatchedCacheMetadata,","highlight_start":9,"highlight_end":23}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":6827,"byte_end":6841,"line_start":241,"line_end":241,"column_start":9,"column_end":23,"is_primary":true,"text":[{"text":"        cache_metadata: &BatchedCacheMetadata,","highlight_start":9,"highlight_end":23}],"label":null,"suggested_replacement":"_cache_metadata","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `cache_metadata`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/mistral.rs:241:9\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m241\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         cache_metadata: &BatchedCacheMetadata,\n    \u001b[1m\u001b[94m|\u001b[0m         \u001b[1m\u001b[33m^^^^^^^^^^^^^^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_cache_metadata`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `is_prefill`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":6874,"byte_end":6884,"line_start":242,"line_end":242,"column_start":9,"column_end":19,"is_primary":true,"text":[{"text":"        is_prefill: bool,","highlight_start":9,"highlight_end":19}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":6874,"byte_end":6884,"line_start":242,"line_end":242,"column_start":9,"column_end":19,"is_primary":true,"text":[{"text":"        is_prefill: bool,","highlight_start":9,"highlight_end":19}],"label":null,"suggested_replacement":"_is_prefill","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `is_prefill`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/mistral.rs:242:9\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m242\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         is_prefill: bool,\n    \u001b[1m\u001b[94m|\u001b[0m         \u001b[1m\u001b[33m^^^^^^^^^^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_is_prefill`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `v`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":7036,"byte_end":7037,"line_start":246,"line_end":246,"column_start":13,"column_end":14,"is_primary":true,"text":[{"text":"        let v = self.v_proj.forward(hidden_states)?;","highlight_start":13,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":7036,"byte_end":7037,"line_start":246,"line_end":246,"column_start":13,"column_end":14,"is_primary":true,"text":[{"text":"        let v = self.v_proj.forward(hidden_states)?;","highlight_start":13,"highlight_end":14}],"label":null,"suggested_replacement":"_v","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `v`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/mistral.rs:246:13\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m246\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         let v = self.v_proj.forward(hidden_states)?;\n    \u001b[1m\u001b[94m|\u001b[0m             \u001b[1m\u001b[33m^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_v`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `k`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":7094,"byte_end":7095,"line_start":248,"line_end":248,"column_start":17,"column_end":18,"is_primary":true,"text":[{"text":"        let (q, k) = self.rotary_emb.apply(&q, &k, positions)?;","highlight_start":17,"highlight_end":18}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":7094,"byte_end":7095,"line_start":248,"line_end":248,"column_start":17,"column_end":18,"is_primary":true,"text":[{"text":"        let (q, k) = self.rotary_emb.apply(&q, &k, positions)?;","highlight_start":17,"highlight_end":18}],"label":null,"suggested_replacement":"_k","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `k`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/mistral.rs:248:17\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m248\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         let (q, k) = self.rotary_emb.apply(&q, &k, positions)?;\n    \u001b[1m\u001b[94m|\u001b[0m                 \u001b[1m\u001b[33m^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_k`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `up`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":8480,"byte_end":8482,"line_start":295,"line_end":295,"column_start":13,"column_end":15,"is_primary":true,"text":[{"text":"        let up = self.up_proj.forward(hidden_states)?;","highlight_start":13,"highlight_end":15}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":8480,"byte_end":8482,"line_start":295,"line_end":295,"column_start":13,"column_end":15,"is_primary":true,"text":[{"text":"        let up = self.up_proj.forward(hidden_states)?;","highlight_start":13,"highlight_end":15}],"label":null,"suggested_replacement":"_up","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `up`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/mistral.rs:295:13\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m295\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         let up = self.up_proj.forward(hidden_states)?;\n    \u001b[1m\u001b[94m|\u001b[0m             \u001b[1m\u001b[33m^^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_up`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `mlp_output`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/phi.rs","byte_start":4420,"byte_end":4430,"line_start":153,"line_end":153,"column_start":13,"column_end":23,"is_primary":true,"text":[{"text":"        let mlp_output = self.mlp.forward(&normed)?;","highlight_start":13,"highlight_end":23}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/phi.rs","byte_start":4420,"byte_end":4430,"line_start":153,"line_end":153,"column_start":13,"column_end":23,"is_primary":true,"text":[{"text":"        let mlp_output = self.mlp.forward(&normed)?;","highlight_start":13,"highlight_end":23}],"label":null,"suggested_replacement":"_mlp_output","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `mlp_output`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/phi.rs:153:13\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m153\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         let mlp_output = self.mlp.forward(&normed)?;\n    \u001b[1m\u001b[94m|\u001b[0m             \u001b[1m\u001b[33m^^^^^^^^^^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_mlp_output`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `v`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/phi.rs","byte_start":7383,"byte_end":7384,"line_start":253,"line_end":253,"column_start":13,"column_end":14,"is_primary":true,"text":[{"text":"        let v = self.v_proj.forward(hidden_states)?;","highlight_start":13,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/phi.rs","byte_start":7383,"byte_end":7384,"line_start":253,"line_end":253,"column_start":13,"column_end":14,"is_primary":true,"text":[{"text":"        let v = self.v_proj.forward(hidden_states)?;","highlight_start":13,"highlight_end":14}],"label":null,"suggested_replacement":"_v","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `v`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/phi.rs:253:13\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m253\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         let v = self.v_proj.forward(hidden_states)?;\n    \u001b[1m\u001b[94m|\u001b[0m             \u001b[1m\u001b[33m^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_v`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `k`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/phi.rs","byte_start":7441,"byte_end":7442,"line_start":255,"line_end":255,"column_start":17,"column_end":18,"is_primary":true,"text":[{"text":"        let (q, k) = self.rotary_emb.apply(&q, &k, positions)?;","highlight_start":17,"highlight_end":18}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/phi.rs","byte_start":7441,"byte_end":7442,"line_start":255,"line_end":255,"column_start":17,"column_end":18,"is_primary":true,"text":[{"text":"        let (q, k) = self.rotary_emb.apply(&q, &k, positions)?;","highlight_start":17,"highlight_end":18}],"label":null,"suggested_replacement":"_k","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `k`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/phi.rs:255:17\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m255\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         let (q, k) = self.rotary_emb.apply(&q, &k, positions)?;\n    \u001b[1m\u001b[94m|\u001b[0m                 \u001b[1m\u001b[33m^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_k`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `v`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/qwen.rs","byte_start":6823,"byte_end":6824,"line_start":235,"line_end":235,"column_start":13,"column_end":14,"is_primary":true,"text":[{"text":"        let v = self.v_proj.forward(hidden_states)?;","highlight_start":13,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/qwen.rs","byte_start":6823,"byte_end":6824,"line_start":235,"line_end":235,"column_start":13,"column_end":14,"is_primary":true,"text":[{"text":"        let v = self.v_proj.forward(hidden_states)?;","highlight_start":13,"highlight_end":14}],"label":null,"suggested_replacement":"_v","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `v`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/qwen.rs:235:13\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m235\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         let v = self.v_proj.forward(hidden_states)?;\n    \u001b[1m\u001b[94m|\u001b[0m             \u001b[1m\u001b[33m^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_v`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `k`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/qwen.rs","byte_start":6881,"byte_end":6882,"line_start":237,"line_end":237,"column_start":17,"column_end":18,"is_primary":true,"text":[{"text":"        let (q, k) = self.rotary_emb.apply(&q, &k, positions)?;","highlight_start":17,"highlight_end":18}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/qwen.rs","byte_start":6881,"byte_end":6882,"line_start":237,"line_end":237,"column_start":17,"column_end":18,"is_primary":true,"text":[{"text":"        let (q, k) = self.rotary_emb.apply(&q, &k, positions)?;","highlight_start":17,"highlight_end":18}],"label":null,"suggested_replacement":"_k","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `k`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/qwen.rs:237:17\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m237\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         let (q, k) = self.rotary_emb.apply(&q, &k, positions)?;\n    \u001b[1m\u001b[94m|\u001b[0m                 \u001b[1m\u001b[33m^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_k`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `weights_path`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/mod.rs","byte_start":1677,"byte_end":1689,"line_start":66,"line_end":66,"column_start":5,"column_end":17,"is_primary":true,"text":[{"text":"    weights_path: &std::path::Path,","highlight_start":5,"highlight_end":17}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/architectures/mod.rs","byte_start":1677,"byte_end":1689,"line_start":66,"line_end":66,"column_start":5,"column_end":17,"is_primary":true,"text":[{"text":"    weights_path: &std::path::Path,","highlight_start":5,"highlight_end":17}],"label":null,"suggested_replacement":"_weights_path","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `weights_path`\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/mod.rs:66:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m66\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     weights_path: &std::path::Path,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_weights_path`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `positions`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":3456,"byte_end":3465,"line_start":151,"line_end":151,"column_start":9,"column_end":18,"is_primary":true,"text":[{"text":"        positions: &[usize],","highlight_start":9,"highlight_end":18}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":3456,"byte_end":3465,"line_start":151,"line_end":151,"column_start":9,"column_end":18,"is_primary":true,"text":[{"text":"        positions: &[usize],","highlight_start":9,"highlight_end":18}],"label":null,"suggested_replacement":"_positions","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `positions`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/attention.rs:151:9\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m151\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         positions: &[usize],\n    \u001b[1m\u001b[94m|\u001b[0m         \u001b[1m\u001b[33m^^^^^^^^^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_positions`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `attn_input`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":3485,"byte_end":3495,"line_start":152,"line_end":152,"column_start":9,"column_end":19,"is_primary":true,"text":[{"text":"        attn_input: &PagedAttentionInput,","highlight_start":9,"highlight_end":19}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":3485,"byte_end":3495,"line_start":152,"line_end":152,"column_start":9,"column_end":19,"is_primary":true,"text":[{"text":"        attn_input: &PagedAttentionInput,","highlight_start":9,"highlight_end":19}],"label":null,"suggested_replacement":"_attn_input","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `attn_input`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/attention.rs:152:9\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m152\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         attn_input: &PagedAttentionInput,\n    \u001b[1m\u001b[94m|\u001b[0m         \u001b[1m\u001b[33m^^^^^^^^^^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_attn_input`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `positions`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":4248,"byte_end":4257,"line_start":180,"line_end":180,"column_start":9,"column_end":18,"is_primary":true,"text":[{"text":"        positions: &[usize],","highlight_start":9,"highlight_end":18}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":4248,"byte_end":4257,"line_start":180,"line_end":180,"column_start":9,"column_end":18,"is_primary":true,"text":[{"text":"        positions: &[usize],","highlight_start":9,"highlight_end":18}],"label":null,"suggested_replacement":"_positions","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `positions`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/attention.rs:180:9\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m180\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         positions: &[usize],\n    \u001b[1m\u001b[94m|\u001b[0m         \u001b[1m\u001b[33m^^^^^^^^^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_positions`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `attn_input`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":4277,"byte_end":4287,"line_start":181,"line_end":181,"column_start":9,"column_end":19,"is_primary":true,"text":[{"text":"        attn_input: &PagedAttentionInput,","highlight_start":9,"highlight_end":19}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":4277,"byte_end":4287,"line_start":181,"line_end":181,"column_start":9,"column_end":19,"is_primary":true,"text":[{"text":"        attn_input: &PagedAttentionInput,","highlight_start":9,"highlight_end":19}],"label":null,"suggested_replacement":"_attn_input","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `attn_input`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/attention.rs:181:9\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m181\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         attn_input: &PagedAttentionInput,\n    \u001b[1m\u001b[94m|\u001b[0m         \u001b[1m\u001b[33m^^^^^^^^^^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_attn_input`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `positions`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":6139,"byte_end":6148,"line_start":253,"line_end":253,"column_start":9,"column_end":18,"is_primary":true,"text":[{"text":"        positions: &[usize],","highlight_start":9,"highlight_end":18}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":6139,"byte_end":6148,"line_start":253,"line_end":253,"column_start":9,"column_end":18,"is_primary":true,"text":[{"text":"        positions: &[usize],","highlight_start":9,"highlight_end":18}],"label":null,"suggested_replacement":"_positions","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `positions`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/attention.rs:253:9\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m253\u001b[0m \u001b[1m\u001b[94m|\u001b[0m         positions: &[usize],\n    \u001b[1m\u001b[94m|\u001b[0m         \u001b[1m\u001b[33m^^^^^^^^^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_positions`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `residual`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/normalization.rs","byte_start":4140,"byte_end":4148,"line_start":170,"line_end":170,"column_start":43,"column_end":51,"is_primary":true,"text":[{"text":"    pub fn forward(&self, input: &Tensor, residual: &Tensor) -> Result<(Tensor, Tensor)> {","highlight_start":43,"highlight_end":51}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/layers/normalization.rs","byte_start":4140,"byte_end":4148,"line_start":170,"line_end":170,"column_start":43,"column_end":51,"is_primary":true,"text":[{"text":"    pub fn forward(&self, input: &Tensor, residual: &Tensor) -> Result<(Tensor, Tensor)> {","highlight_start":43,"highlight_end":51}],"label":null,"suggested_replacement":"_residual","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `residual`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/normalization.rs:170:43\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m170\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     pub fn forward(&self, input: &Tensor, residual: &Tensor) -> Result<(Tensor, Tensor)> {\n    \u001b[1m\u001b[94m|\u001b[0m                                           \u001b[1m\u001b[33m^^^^^^^^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_residual`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `arr_type`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":13001,"byte_end":13009,"line_start":450,"line_end":450,"column_start":17,"column_end":25,"is_primary":true,"text":[{"text":"            let arr_type = read_u32(reader)?;","highlight_start":17,"highlight_end":25}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":13001,"byte_end":13009,"line_start":450,"line_end":450,"column_start":17,"column_end":25,"is_primary":true,"text":[{"text":"            let arr_type = read_u32(reader)?;","highlight_start":17,"highlight_end":25}],"label":null,"suggested_replacement":"_arr_type","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: unused variable: `arr_type`\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:450:17\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m450\u001b[0m \u001b[1m\u001b[94m|\u001b[0m             let arr_type = read_u32(reader)?;\n    \u001b[1m\u001b[94m|\u001b[0m                 \u001b[1m\u001b[33m^^^^^^^^\u001b[0m \u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_arr_type`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"field `layer_idx` is never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":3662,"byte_end":3679,"line_start":136,"line_end":136,"column_start":8,"column_end":25,"is_primary":false,"text":[{"text":"struct LlamaDecoderLayer {","highlight_start":8,"highlight_end":25}],"label":"field in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":3706,"byte_end":3715,"line_start":138,"line_end":138,"column_start":5,"column_end":14,"is_primary":true,"text":[{"text":"    layer_idx: usize,","highlight_start":5,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`#[warn(dead_code)]` (part of `#[warn(unused)]`) on by default","code":null,"level":"note","spans":[],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: field `layer_idx` is never read\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/llama.rs:138:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m136\u001b[0m \u001b[1m\u001b[94m|\u001b[0m struct LlamaDecoderLayer {\n    \u001b[1m\u001b[94m|\u001b[0m        \u001b[1m\u001b[94m-----------------\u001b[0m \u001b[1m\u001b[94mfield in this struct\u001b[0m\n\u001b[1m\u001b[94m137\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     /// Layer index\n\u001b[1m\u001b[94m138\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     layer_idx: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^\u001b[0m\n    \u001b[1m\u001b[94m|\u001b[0m\n    \u001b[1m\u001b[94m= \u001b[0m\u001b[1mnote\u001b[0m: `#[warn(dead_code)]` (part of `#[warn(unused)]`) on by default\n\n"}
{"$message_type":"diagnostic","message":"fields `num_heads`, `num_kv_heads`, `head_dim`, and `scale` are never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":5825,"byte_end":5839,"line_start":210,"line_end":210,"column_start":8,"column_end":22,"is_primary":false,"text":[{"text":"struct LlamaAttention {","highlight_start":8,"highlight_end":22}],"label":"fields in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":6113,"byte_end":6122,"line_start":227,"line_end":227,"column_start":5,"column_end":14,"is_primary":true,"text":[{"text":"    num_heads: usize,","highlight_start":5,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":6163,"byte_end":6175,"line_start":230,"line_end":230,"column_start":5,"column_end":17,"is_primary":true,"text":[{"text":"    num_kv_heads: usize,","highlight_start":5,"highlight_end":17}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":6212,"byte_end":6220,"line_start":233,"line_end":233,"column_start":5,"column_end":13,"is_primary":true,"text":[{"text":"    head_dim: usize,","highlight_start":5,"highlight_end":13}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/llama.rs","byte_start":6257,"byte_end":6262,"line_start":236,"line_end":236,"column_start":5,"column_end":10,"is_primary":true,"text":[{"text":"    scale: f32,","highlight_start":5,"highlight_end":10}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: fields `num_heads`, `num_kv_heads`, `head_dim`, and `scale` are never read\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/llama.rs:227:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m210\u001b[0m \u001b[1m\u001b[94m|\u001b[0m struct LlamaAttention {\n    \u001b[1m\u001b[94m|\u001b[0m        \u001b[1m\u001b[94m--------------\u001b[0m \u001b[1m\u001b[94mfields in this struct\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m227\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     num_heads: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m230\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     num_kv_heads: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m233\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     head_dim: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m236\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     scale: f32,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"field `layer_idx` is never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":3268,"byte_end":3287,"line_start":123,"line_end":123,"column_start":8,"column_end":27,"is_primary":false,"text":[{"text":"struct MistralDecoderLayer {","highlight_start":8,"highlight_end":27}],"label":"field in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":3294,"byte_end":3303,"line_start":124,"line_end":124,"column_start":5,"column_end":14,"is_primary":true,"text":[{"text":"    layer_idx: usize,","highlight_start":5,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: field `layer_idx` is never read\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/mistral.rs:124:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m123\u001b[0m \u001b[1m\u001b[94m|\u001b[0m struct MistralDecoderLayer {\n    \u001b[1m\u001b[94m|\u001b[0m        \u001b[1m\u001b[94m-------------------\u001b[0m \u001b[1m\u001b[94mfield in this struct\u001b[0m\n\u001b[1m\u001b[94m124\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     layer_idx: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"fields `num_heads`, `num_kv_heads`, `head_dim`, `sliding_window`, and `scale` are never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":4931,"byte_end":4947,"line_start":176,"line_end":176,"column_start":8,"column_end":24,"is_primary":false,"text":[{"text":"struct MistralAttention {","highlight_start":8,"highlight_end":24}],"label":"fields in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":5067,"byte_end":5076,"line_start":182,"line_end":182,"column_start":5,"column_end":14,"is_primary":true,"text":[{"text":"    num_heads: usize,","highlight_start":5,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":5089,"byte_end":5101,"line_start":183,"line_end":183,"column_start":5,"column_end":17,"is_primary":true,"text":[{"text":"    num_kv_heads: usize,","highlight_start":5,"highlight_end":17}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":5114,"byte_end":5122,"line_start":184,"line_end":184,"column_start":5,"column_end":13,"is_primary":true,"text":[{"text":"    head_dim: usize,","highlight_start":5,"highlight_end":13}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":5135,"byte_end":5149,"line_start":185,"line_end":185,"column_start":5,"column_end":19,"is_primary":true,"text":[{"text":"    sliding_window: Option<usize>,","highlight_start":5,"highlight_end":19}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/mistral.rs","byte_start":5170,"byte_end":5175,"line_start":186,"line_end":186,"column_start":5,"column_end":10,"is_primary":true,"text":[{"text":"    scale: f32,","highlight_start":5,"highlight_end":10}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: fields `num_heads`, `num_kv_heads`, `head_dim`, `sliding_window`, and `scale` are never read\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/mistral.rs:182:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m176\u001b[0m \u001b[1m\u001b[94m|\u001b[0m struct MistralAttention {\n    \u001b[1m\u001b[94m|\u001b[0m        \u001b[1m\u001b[94m----------------\u001b[0m \u001b[1m\u001b[94mfields in this struct\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m182\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     num_heads: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m183\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     num_kv_heads: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m184\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     head_dim: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m185\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     sliding_window: Option<usize>,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m186\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     scale: f32,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"field `layer_idx` is never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/phi.rs","byte_start":3159,"byte_end":3174,"line_start":112,"line_end":112,"column_start":8,"column_end":23,"is_primary":false,"text":[{"text":"struct PhiDecoderLayer {","highlight_start":8,"highlight_end":23}],"label":"field in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/phi.rs","byte_start":3181,"byte_end":3190,"line_start":113,"line_end":113,"column_start":5,"column_end":14,"is_primary":true,"text":[{"text":"    layer_idx: usize,","highlight_start":5,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: field `layer_idx` is never read\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/phi.rs:113:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m112\u001b[0m \u001b[1m\u001b[94m|\u001b[0m struct PhiDecoderLayer {\n    \u001b[1m\u001b[94m|\u001b[0m        \u001b[1m\u001b[94m---------------\u001b[0m \u001b[1m\u001b[94mfield in this struct\u001b[0m\n\u001b[1m\u001b[94m113\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     layer_idx: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"fields `num_heads`, `num_kv_heads`, `head_dim`, and `scale` are never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/phi.rs","byte_start":4578,"byte_end":4590,"line_start":160,"line_end":160,"column_start":8,"column_end":20,"is_primary":false,"text":[{"text":"struct PhiAttention {","highlight_start":8,"highlight_end":20}],"label":"fields in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/phi.rs","byte_start":4749,"byte_end":4758,"line_start":166,"line_end":166,"column_start":5,"column_end":14,"is_primary":true,"text":[{"text":"    num_heads: usize,","highlight_start":5,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/phi.rs","byte_start":4771,"byte_end":4783,"line_start":167,"line_end":167,"column_start":5,"column_end":17,"is_primary":true,"text":[{"text":"    num_kv_heads: usize,","highlight_start":5,"highlight_end":17}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/phi.rs","byte_start":4796,"byte_end":4804,"line_start":168,"line_end":168,"column_start":5,"column_end":13,"is_primary":true,"text":[{"text":"    head_dim: usize,","highlight_start":5,"highlight_end":13}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/phi.rs","byte_start":4817,"byte_end":4822,"line_start":169,"line_end":169,"column_start":5,"column_end":10,"is_primary":true,"text":[{"text":"    scale: f32,","highlight_start":5,"highlight_end":10}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: fields `num_heads`, `num_kv_heads`, `head_dim`, and `scale` are never read\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/phi.rs:166:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m160\u001b[0m \u001b[1m\u001b[94m|\u001b[0m struct PhiAttention {\n    \u001b[1m\u001b[94m|\u001b[0m        \u001b[1m\u001b[94m------------\u001b[0m \u001b[1m\u001b[94mfields in this struct\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m166\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     num_heads: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m167\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     num_kv_heads: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m168\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     head_dim: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m169\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     scale: f32,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"field `layer_idx` is never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/qwen.rs","byte_start":2919,"byte_end":2935,"line_start":106,"line_end":106,"column_start":8,"column_end":24,"is_primary":false,"text":[{"text":"struct QwenDecoderLayer {","highlight_start":8,"highlight_end":24}],"label":"field in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/qwen.rs","byte_start":2942,"byte_end":2951,"line_start":107,"line_end":107,"column_start":5,"column_end":14,"is_primary":true,"text":[{"text":"    layer_idx: usize,","highlight_start":5,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: field `layer_idx` is never read\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/qwen.rs:107:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m106\u001b[0m \u001b[1m\u001b[94m|\u001b[0m struct QwenDecoderLayer {\n    \u001b[1m\u001b[94m|\u001b[0m        \u001b[1m\u001b[94m----------------\u001b[0m \u001b[1m\u001b[94mfield in this struct\u001b[0m\n\u001b[1m\u001b[94m107\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     layer_idx: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"fields `num_heads`, `num_kv_heads`, `head_dim`, `scale`, and `use_bias` are never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/qwen.rs","byte_start":4430,"byte_end":4443,"line_start":153,"line_end":153,"column_start":8,"column_end":21,"is_primary":false,"text":[{"text":"struct QwenAttention {","highlight_start":8,"highlight_end":21}],"label":"fields in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/qwen.rs","byte_start":4563,"byte_end":4572,"line_start":159,"line_end":159,"column_start":5,"column_end":14,"is_primary":true,"text":[{"text":"    num_heads: usize,","highlight_start":5,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/qwen.rs","byte_start":4585,"byte_end":4597,"line_start":160,"line_end":160,"column_start":5,"column_end":17,"is_primary":true,"text":[{"text":"    num_kv_heads: usize,","highlight_start":5,"highlight_end":17}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/qwen.rs","byte_start":4610,"byte_end":4618,"line_start":161,"line_end":161,"column_start":5,"column_end":13,"is_primary":true,"text":[{"text":"    head_dim: usize,","highlight_start":5,"highlight_end":13}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/qwen.rs","byte_start":4631,"byte_end":4636,"line_start":162,"line_end":162,"column_start":5,"column_end":10,"is_primary":true,"text":[{"text":"    scale: f32,","highlight_start":5,"highlight_end":10}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/architectures/qwen.rs","byte_start":4647,"byte_end":4655,"line_start":163,"line_end":163,"column_start":5,"column_end":13,"is_primary":true,"text":[{"text":"    use_bias: bool,","highlight_start":5,"highlight_end":13}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: fields `num_heads`, `num_kv_heads`, `head_dim`, `scale`, and `use_bias` are never read\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/qwen.rs:159:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m153\u001b[0m \u001b[1m\u001b[94m|\u001b[0m struct QwenAttention {\n    \u001b[1m\u001b[94m|\u001b[0m        \u001b[1m\u001b[94m-------------\u001b[0m \u001b[1m\u001b[94mfields in this struct\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m159\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     num_heads: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m160\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     num_kv_heads: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m161\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     head_dim: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m162\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     scale: f32,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^\u001b[0m\n\u001b[1m\u001b[94m163\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     use_bias: bool,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"fields `q_proj`, `k_proj`, `v_proj`, `o_proj`, and `rotary_emb` are never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":1808,"byte_end":1817,"line_start":71,"line_end":71,"column_start":12,"column_end":21,"is_primary":false,"text":[{"text":"pub struct Attention {","highlight_start":12,"highlight_end":21}],"label":"fields in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":1901,"byte_end":1907,"line_start":76,"line_end":76,"column_start":5,"column_end":11,"is_primary":true,"text":[{"text":"    q_proj: Tensor,","highlight_start":5,"highlight_end":11}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":1945,"byte_end":1951,"line_start":79,"line_end":79,"column_start":5,"column_end":11,"is_primary":true,"text":[{"text":"    k_proj: Tensor,","highlight_start":5,"highlight_end":11}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":1991,"byte_end":1997,"line_start":82,"line_end":82,"column_start":5,"column_end":11,"is_primary":true,"text":[{"text":"    v_proj: Tensor,","highlight_start":5,"highlight_end":11}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":2038,"byte_end":2044,"line_start":85,"line_end":85,"column_start":5,"column_end":11,"is_primary":true,"text":[{"text":"    o_proj: Tensor,","highlight_start":5,"highlight_end":11}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":2320,"byte_end":2330,"line_start":100,"line_end":100,"column_start":5,"column_end":15,"is_primary":true,"text":[{"text":"    rotary_emb: RotaryEmbedding,","highlight_start":5,"highlight_end":15}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`Attention` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis","code":null,"level":"note","spans":[],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: fields `q_proj`, `k_proj`, `v_proj`, `o_proj`, and `rotary_emb` are never read\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/attention.rs:76:5\n    \u001b[1m\u001b[94m|\u001b[0m\n \u001b[1m\u001b[94m71\u001b[0m \u001b[1m\u001b[94m|\u001b[0m pub struct Attention {\n    \u001b[1m\u001b[94m|\u001b[0m            \u001b[1m\u001b[94m---------\u001b[0m \u001b[1m\u001b[94mfields in this struct\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n \u001b[1m\u001b[94m76\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     q_proj: Tensor,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n \u001b[1m\u001b[94m79\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     k_proj: Tensor,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n \u001b[1m\u001b[94m82\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     v_proj: Tensor,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n \u001b[1m\u001b[94m85\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     o_proj: Tensor,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m100\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     rotary_emb: RotaryEmbedding,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^\u001b[0m\n    \u001b[1m\u001b[94m|\u001b[0m\n    \u001b[1m\u001b[94m= \u001b[0m\u001b[1mnote\u001b[0m: `Attention` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis\n\n"}
{"$message_type":"diagnostic","message":"field `base` is never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":4750,"byte_end":4765,"line_start":199,"line_end":199,"column_start":12,"column_end":27,"is_primary":false,"text":[{"text":"pub struct RotaryEmbedding {","highlight_start":12,"highlight_end":27}],"label":"field in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":4893,"byte_end":4897,"line_start":207,"line_end":207,"column_start":5,"column_end":9,"is_primary":true,"text":[{"text":"    base: f32,","highlight_start":5,"highlight_end":9}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`RotaryEmbedding` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis","code":null,"level":"note","spans":[],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: field `base` is never read\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/attention.rs:207:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m199\u001b[0m \u001b[1m\u001b[94m|\u001b[0m pub struct RotaryEmbedding {\n    \u001b[1m\u001b[94m|\u001b[0m            \u001b[1m\u001b[94m---------------\u001b[0m \u001b[1m\u001b[94mfield in this struct\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m207\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     base: f32,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^\u001b[0m\n    \u001b[1m\u001b[94m|\u001b[0m\n    \u001b[1m\u001b[94m= \u001b[0m\u001b[1mnote\u001b[0m: `RotaryEmbedding` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis\n\n"}
{"$message_type":"diagnostic","message":"function `rotate_half` is never used","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":7105,"byte_end":7116,"line_start":281,"line_end":281,"column_start":4,"column_end":15,"is_primary":true,"text":[{"text":"fn rotate_half(x: &[f32]) -> Vec<f32> {","highlight_start":4,"highlight_end":15}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: function `rotate_half` is never used\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/attention.rs:281:4\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m281\u001b[0m \u001b[1m\u001b[94m|\u001b[0m fn rotate_half(x: &[f32]) -> Vec<f32> {\n    \u001b[1m\u001b[94m|\u001b[0m    \u001b[1m\u001b[33m^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"fields `original_max_position_embeddings` and `attention_factor` are never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":7499,"byte_end":7510,"line_start":299,"line_end":299,"column_start":12,"column_end":23,"is_primary":false,"text":[{"text":"pub struct YaRNScaling {","highlight_start":12,"highlight_end":23}],"label":"fields in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":7558,"byte_end":7590,"line_start":301,"line_end":301,"column_start":5,"column_end":37,"is_primary":true,"text":[{"text":"    original_max_position_embeddings: usize,","highlight_start":5,"highlight_end":37}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/attention.rs","byte_start":7669,"byte_end":7685,"line_start":307,"line_end":307,"column_start":5,"column_end":21,"is_primary":true,"text":[{"text":"    attention_factor: f32,","highlight_start":5,"highlight_end":21}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`YaRNScaling` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis","code":null,"level":"note","spans":[],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: fields `original_max_position_embeddings` and `attention_factor` are never read\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/attention.rs:301:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m299\u001b[0m \u001b[1m\u001b[94m|\u001b[0m pub struct YaRNScaling {\n    \u001b[1m\u001b[94m|\u001b[0m            \u001b[1m\u001b[94m-----------\u001b[0m \u001b[1m\u001b[94mfields in this struct\u001b[0m\n\u001b[1m\u001b[94m300\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     /// Original max position embeddings\n\u001b[1m\u001b[94m301\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     original_max_position_embeddings: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m307\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     attention_factor: f32,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^^^^^^\u001b[0m\n    \u001b[1m\u001b[94m|\u001b[0m\n    \u001b[1m\u001b[94m= \u001b[0m\u001b[1mnote\u001b[0m: `YaRNScaling` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis\n\n"}
{"$message_type":"diagnostic","message":"fields `vocab_size`, `vocab_size_per_gpu`, `tp_rank`, and `tp_size` are never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/embedding.rs","byte_start":3498,"byte_end":3520,"line_start":125,"line_end":125,"column_start":12,"column_end":34,"is_primary":false,"text":[{"text":"pub struct VocabParallelEmbedding {","highlight_start":12,"highlight_end":34}],"label":"fields in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/embedding.rs","byte_start":3610,"byte_end":3620,"line_start":130,"line_end":130,"column_start":5,"column_end":15,"is_primary":true,"text":[{"text":"    vocab_size: usize,","highlight_start":5,"highlight_end":15}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/embedding.rs","byte_start":3674,"byte_end":3692,"line_start":133,"line_end":133,"column_start":5,"column_end":23,"is_primary":true,"text":[{"text":"    vocab_size_per_gpu: usize,","highlight_start":5,"highlight_end":23}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/embedding.rs","byte_start":3914,"byte_end":3921,"line_start":145,"line_end":145,"column_start":5,"column_end":12,"is_primary":true,"text":[{"text":"    tp_rank: usize,","highlight_start":5,"highlight_end":12}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/embedding.rs","byte_start":3970,"byte_end":3977,"line_start":148,"line_end":148,"column_start":5,"column_end":12,"is_primary":true,"text":[{"text":"    tp_size: usize,","highlight_start":5,"highlight_end":12}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`VocabParallelEmbedding` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis","code":null,"level":"note","spans":[],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: fields `vocab_size`, `vocab_size_per_gpu`, `tp_rank`, and `tp_size` are never read\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/embedding.rs:130:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m125\u001b[0m \u001b[1m\u001b[94m|\u001b[0m pub struct VocabParallelEmbedding {\n    \u001b[1m\u001b[94m|\u001b[0m            \u001b[1m\u001b[94m----------------------\u001b[0m \u001b[1m\u001b[94mfields in this struct\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m130\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     vocab_size: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m133\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     vocab_size_per_gpu: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m145\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     tp_rank: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m148\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     tp_size: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^\u001b[0m\n    \u001b[1m\u001b[94m|\u001b[0m\n    \u001b[1m\u001b[94m= \u001b[0m\u001b[1mnote\u001b[0m: `VocabParallelEmbedding` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis\n\n"}
{"$message_type":"diagnostic","message":"fields `weight` and `hidden_size` are never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/embedding.rs","byte_start":5931,"byte_end":5937,"line_start":218,"line_end":218,"column_start":12,"column_end":18,"is_primary":false,"text":[{"text":"pub struct LMHead {","highlight_start":12,"highlight_end":18}],"label":"fields in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/embedding.rs","byte_start":6032,"byte_end":6038,"line_start":221,"line_end":221,"column_start":5,"column_end":11,"is_primary":true,"text":[{"text":"    weight: Tensor,","highlight_start":5,"highlight_end":11}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/embedding.rs","byte_start":6121,"byte_end":6132,"line_start":227,"line_end":227,"column_start":5,"column_end":16,"is_primary":true,"text":[{"text":"    hidden_size: usize,","highlight_start":5,"highlight_end":16}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`LMHead` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis","code":null,"level":"note","spans":[],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: fields `weight` and `hidden_size` are never read\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/embedding.rs:221:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m218\u001b[0m \u001b[1m\u001b[94m|\u001b[0m pub struct LMHead {\n    \u001b[1m\u001b[94m|\u001b[0m            \u001b[1m\u001b[94m------\u001b[0m \u001b[1m\u001b[94mfields in this struct\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m221\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     weight: Tensor,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m227\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     hidden_size: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^\u001b[0m\n    \u001b[1m\u001b[94m|\u001b[0m\n    \u001b[1m\u001b[94m= \u001b[0m\u001b[1mnote\u001b[0m: `LMHead` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis\n\n"}
{"$message_type":"diagnostic","message":"fields `config`, `up_proj`, and `down_proj` are never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":1866,"byte_end":1869,"line_start":80,"line_end":80,"column_start":12,"column_end":15,"is_primary":false,"text":[{"text":"pub struct Mlp {","highlight_start":12,"highlight_end":15}],"label":"fields in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":1898,"byte_end":1904,"line_start":82,"line_end":82,"column_start":5,"column_end":11,"is_primary":true,"text":[{"text":"    config: MlpConfig,","highlight_start":5,"highlight_end":11}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":1944,"byte_end":1951,"line_start":85,"line_end":85,"column_start":5,"column_end":12,"is_primary":true,"text":[{"text":"    up_proj: Linear,","highlight_start":5,"highlight_end":12}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":1990,"byte_end":1999,"line_start":88,"line_end":88,"column_start":5,"column_end":14,"is_primary":true,"text":[{"text":"    down_proj: Linear,","highlight_start":5,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`Mlp` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis","code":null,"level":"note","spans":[],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: fields `config`, `up_proj`, and `down_proj` are never read\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/mlp.rs:82:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m80\u001b[0m \u001b[1m\u001b[94m|\u001b[0m pub struct Mlp {\n   \u001b[1m\u001b[94m|\u001b[0m            \u001b[1m\u001b[94m---\u001b[0m \u001b[1m\u001b[94mfields in this struct\u001b[0m\n\u001b[1m\u001b[94m81\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     /// Configuration\n\u001b[1m\u001b[94m82\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     config: MlpConfig,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m85\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     up_proj: Linear,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m88\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     down_proj: Linear,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^\u001b[0m\n   \u001b[1m\u001b[94m|\u001b[0m\n   \u001b[1m\u001b[94m= \u001b[0m\u001b[1mnote\u001b[0m: `Mlp` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis\n\n"}
{"$message_type":"diagnostic","message":"fields `config`, `gate_proj`, `up_proj`, and `down_proj` are never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":2894,"byte_end":2902,"line_start":123,"line_end":123,"column_start":12,"column_end":20,"is_primary":false,"text":[{"text":"pub struct GatedMlp {","highlight_start":12,"highlight_end":20}],"label":"fields in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":2931,"byte_end":2937,"line_start":125,"line_end":125,"column_start":5,"column_end":11,"is_primary":true,"text":[{"text":"    config: MlpConfig,","highlight_start":5,"highlight_end":11}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":2979,"byte_end":2988,"line_start":128,"line_end":128,"column_start":5,"column_end":14,"is_primary":true,"text":[{"text":"    gate_proj: Linear,","highlight_start":5,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":3025,"byte_end":3032,"line_start":131,"line_end":131,"column_start":5,"column_end":12,"is_primary":true,"text":[{"text":"    up_proj: Linear,","highlight_start":5,"highlight_end":12}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":3071,"byte_end":3080,"line_start":134,"line_end":134,"column_start":5,"column_end":14,"is_primary":true,"text":[{"text":"    down_proj: Linear,","highlight_start":5,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`GatedMlp` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis","code":null,"level":"note","spans":[],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: fields `config`, `gate_proj`, `up_proj`, and `down_proj` are never read\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/mlp.rs:125:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m123\u001b[0m \u001b[1m\u001b[94m|\u001b[0m pub struct GatedMlp {\n    \u001b[1m\u001b[94m|\u001b[0m            \u001b[1m\u001b[94m--------\u001b[0m \u001b[1m\u001b[94mfields in this struct\u001b[0m\n\u001b[1m\u001b[94m124\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     /// Configuration\n\u001b[1m\u001b[94m125\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     config: MlpConfig,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m128\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     gate_proj: Linear,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m131\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     up_proj: Linear,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m134\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     down_proj: Linear,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^\u001b[0m\n    \u001b[1m\u001b[94m|\u001b[0m\n    \u001b[1m\u001b[94m= \u001b[0m\u001b[1mnote\u001b[0m: `GatedMlp` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis\n\n"}
{"$message_type":"diagnostic","message":"fields `config`, `gate_up_proj`, and `down_proj` are never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":3879,"byte_end":3892,"line_start":171,"line_end":171,"column_start":12,"column_end":25,"is_primary":false,"text":[{"text":"pub struct FusedGatedMlp {","highlight_start":12,"highlight_end":25}],"label":"fields in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":3921,"byte_end":3927,"line_start":173,"line_end":173,"column_start":5,"column_end":11,"is_primary":true,"text":[{"text":"    config: MlpConfig,","highlight_start":5,"highlight_end":11}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":3979,"byte_end":3991,"line_start":176,"line_end":176,"column_start":5,"column_end":17,"is_primary":true,"text":[{"text":"    gate_up_proj: Linear,","highlight_start":5,"highlight_end":17}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":4030,"byte_end":4039,"line_start":179,"line_end":179,"column_start":5,"column_end":14,"is_primary":true,"text":[{"text":"    down_proj: Linear,","highlight_start":5,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`FusedGatedMlp` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis","code":null,"level":"note","spans":[],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: fields `config`, `gate_up_proj`, and `down_proj` are never read\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/mlp.rs:173:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m171\u001b[0m \u001b[1m\u001b[94m|\u001b[0m pub struct FusedGatedMlp {\n    \u001b[1m\u001b[94m|\u001b[0m            \u001b[1m\u001b[94m-------------\u001b[0m \u001b[1m\u001b[94mfields in this struct\u001b[0m\n\u001b[1m\u001b[94m172\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     /// Configuration\n\u001b[1m\u001b[94m173\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     config: MlpConfig,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m176\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     gate_up_proj: Linear,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m179\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     down_proj: Linear,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^\u001b[0m\n    \u001b[1m\u001b[94m|\u001b[0m\n    \u001b[1m\u001b[94m= \u001b[0m\u001b[1mnote\u001b[0m: `FusedGatedMlp` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis\n\n"}
{"$message_type":"diagnostic","message":"fields `num_experts_per_tok`, `experts`, and `gate` are never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":4792,"byte_end":4798,"line_start":209,"line_end":209,"column_start":12,"column_end":18,"is_primary":false,"text":[{"text":"pub struct MoeMlp {","highlight_start":12,"highlight_end":18}],"label":"fields in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":4894,"byte_end":4913,"line_start":214,"line_end":214,"column_start":5,"column_end":24,"is_primary":true,"text":[{"text":"    num_experts_per_tok: usize,","highlight_start":5,"highlight_end":24}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":4947,"byte_end":4954,"line_start":217,"line_end":217,"column_start":5,"column_end":12,"is_primary":true,"text":[{"text":"    experts: Vec<GatedMlp>,","highlight_start":5,"highlight_end":12}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/layers/mlp.rs","byte_start":5006,"byte_end":5010,"line_start":220,"line_end":220,"column_start":5,"column_end":9,"is_primary":true,"text":[{"text":"    gate: Linear,","highlight_start":5,"highlight_end":9}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`MoeMlp` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis","code":null,"level":"note","spans":[],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: fields `num_experts_per_tok`, `experts`, and `gate` are never read\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/layers/mlp.rs:214:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m209\u001b[0m \u001b[1m\u001b[94m|\u001b[0m pub struct MoeMlp {\n    \u001b[1m\u001b[94m|\u001b[0m            \u001b[1m\u001b[94m------\u001b[0m \u001b[1m\u001b[94mfields in this struct\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m214\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     num_experts_per_tok: usize,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^^^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m217\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     experts: Vec<GatedMlp>,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m220\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     gate: Linear,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^\u001b[0m\n    \u001b[1m\u001b[94m|\u001b[0m\n    \u001b[1m\u001b[94m= \u001b[0m\u001b[1mnote\u001b[0m: `MoeMlp` has a derived impl for the trait `Debug`, but this is intentionally ignored during dead code analysis\n\n"}
{"$message_type":"diagnostic","message":"method `block_size` is never used","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":1037,"byte_end":1050,"line_start":55,"line_end":55,"column_start":1,"column_end":14,"is_primary":false,"text":[{"text":"impl GgufType {","highlight_start":1,"highlight_end":14}],"label":"method in this implementation","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":2218,"byte_end":2228,"line_start":91,"line_end":91,"column_start":8,"column_end":18,"is_primary":true,"text":[{"text":"    fn block_size(&self) -> usize {","highlight_start":8,"highlight_end":18}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: method `block_size` is never used\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:91:8\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m55\u001b[0m \u001b[1m\u001b[94m|\u001b[0m impl GgufType {\n   \u001b[1m\u001b[94m|\u001b[0m \u001b[1m\u001b[94m-------------\u001b[0m \u001b[1m\u001b[94mmethod in this implementation\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m91\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     fn block_size(&self) -> usize {\n   \u001b[1m\u001b[94m|\u001b[0m        \u001b[1m\u001b[33m^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"method `as_f32` is never used","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":3060,"byte_end":3074,"line_start":127,"line_end":127,"column_start":1,"column_end":15,"is_primary":false,"text":[{"text":"impl GgufValue {","highlight_start":1,"highlight_end":15}],"label":"method in this implementation","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":3366,"byte_end":3372,"line_start":138,"line_end":138,"column_start":8,"column_end":14,"is_primary":true,"text":[{"text":"    fn as_f32(&self) -> Option<f32> {","highlight_start":8,"highlight_end":14}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: method `as_f32` is never used\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:138:8\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m127\u001b[0m \u001b[1m\u001b[94m|\u001b[0m impl GgufValue {\n    \u001b[1m\u001b[94m|\u001b[0m \u001b[1m\u001b[94m--------------\u001b[0m \u001b[1m\u001b[94mmethod in this implementation\u001b[0m\n\u001b[1m\u001b[94m...\u001b[0m\n\u001b[1m\u001b[94m138\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     fn as_f32(&self) -> Option<f32> {\n    \u001b[1m\u001b[94m|\u001b[0m        \u001b[1m\u001b[33m^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"fields `name` and `n_dims` are never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":3753,"byte_end":3767,"line_start":156,"line_end":156,"column_start":8,"column_end":22,"is_primary":false,"text":[{"text":"struct GgufTensorInfo {","highlight_start":8,"highlight_end":22}],"label":"fields in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":3774,"byte_end":3778,"line_start":157,"line_end":157,"column_start":5,"column_end":9,"is_primary":true,"text":[{"text":"    name: String,","highlight_start":5,"highlight_end":9}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":3792,"byte_end":3798,"line_start":158,"line_end":158,"column_start":5,"column_end":11,"is_primary":true,"text":[{"text":"    n_dims: u32,","highlight_start":5,"highlight_end":11}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`GgufTensorInfo` has derived impls for the traits `Clone` and `Debug`, but these are intentionally ignored during dead code analysis","code":null,"level":"note","spans":[],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: fields `name` and `n_dims` are never read\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:157:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m156\u001b[0m \u001b[1m\u001b[94m|\u001b[0m struct GgufTensorInfo {\n    \u001b[1m\u001b[94m|\u001b[0m        \u001b[1m\u001b[94m--------------\u001b[0m \u001b[1m\u001b[94mfields in this struct\u001b[0m\n\u001b[1m\u001b[94m157\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     name: String,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^\u001b[0m\n\u001b[1m\u001b[94m158\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     n_dims: u32,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^\u001b[0m\n    \u001b[1m\u001b[94m|\u001b[0m\n    \u001b[1m\u001b[94m= \u001b[0m\u001b[1mnote\u001b[0m: `GgufTensorInfo` has derived impls for the traits `Clone` and `Debug`, but these are intentionally ignored during dead code analysis\n\n"}
{"$message_type":"diagnostic","message":"field `files` is never read","code":{"code":"dead_code","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/safetensors.rs","byte_start":392,"byte_end":409,"line_start":16,"line_end":16,"column_start":12,"column_end":29,"is_primary":false,"text":[{"text":"pub struct SafeTensorsLoader {","highlight_start":12,"highlight_end":29}],"label":"field in this struct","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"crates/swiftllm-models/src/loaders/safetensors.rs","byte_start":435,"byte_end":440,"line_start":18,"line_end":18,"column_start":5,"column_end":10,"is_primary":true,"text":[{"text":"    files: Vec<PathBuf>,","highlight_start":5,"highlight_end":10}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: field `files` is never read\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/safetensors.rs:18:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m16\u001b[0m \u001b[1m\u001b[94m|\u001b[0m pub struct SafeTensorsLoader {\n   \u001b[1m\u001b[94m|\u001b[0m            \u001b[1m\u001b[94m-----------------\u001b[0m \u001b[1m\u001b[94mfield in this struct\u001b[0m\n\u001b[1m\u001b[94m17\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     /// File paths\n\u001b[1m\u001b[94m18\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     files: Vec<PathBuf>,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for an associated function","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/phi.rs","byte_start":619,"byte_end":666,"line_start":24,"line_end":24,"column_start":5,"column_end":52,"is_primary":true,"text":[{"text":"    pub fn new(config: ModelConfig) -> Result<Self> {","highlight_start":5,"highlight_end":52}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"the lint level is defined here","code":null,"level":"note","spans":[{"file_name":"crates/swiftllm-models/src/lib.rs","byte_start":213,"byte_end":225,"line_start":7,"line_end":7,"column_start":9,"column_end":21,"is_primary":true,"text":[{"text":"#![warn(missing_docs)]","highlight_start":9,"highlight_end":21}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for an associated function\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/phi.rs:24:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m24\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     pub fn new(config: ModelConfig) -> Result<Self> {\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[92mnote\u001b[0m: the lint level is defined here\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/lib.rs:7:9\n   \u001b[1m\u001b[94m|\u001b[0m\n \u001b[1m\u001b[94m7\u001b[0m \u001b[1m\u001b[94m|\u001b[0m #![warn(missing_docs)]\n   \u001b[1m\u001b[94m|\u001b[0m         \u001b[1m\u001b[92m^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for an associated function","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/architectures/qwen.rs","byte_start":600,"byte_end":647,"line_start":24,"line_end":24,"column_start":5,"column_end":52,"is_primary":true,"text":[{"text":"    pub fn new(config: ModelConfig) -> Result<Self> {","highlight_start":5,"highlight_end":52}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for an associated function\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/architectures/qwen.rs:24:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m24\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     pub fn new(config: ModelConfig) -> Result<Self> {\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":633,"byte_end":636,"line_start":25,"line_end":25,"column_start":5,"column_end":8,"is_primary":true,"text":[{"text":"    F32 = 0,","highlight_start":5,"highlight_end":8}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:25:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m25\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     F32 = 0,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":646,"byte_end":649,"line_start":26,"line_end":26,"column_start":5,"column_end":8,"is_primary":true,"text":[{"text":"    F16 = 1,","highlight_start":5,"highlight_end":8}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:26:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m26\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     F16 = 1,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":659,"byte_end":663,"line_start":27,"line_end":27,"column_start":5,"column_end":9,"is_primary":true,"text":[{"text":"    Q4_0 = 2,","highlight_start":5,"highlight_end":9}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:27:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m27\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Q4_0 = 2,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":673,"byte_end":677,"line_start":28,"line_end":28,"column_start":5,"column_end":9,"is_primary":true,"text":[{"text":"    Q4_1 = 3,","highlight_start":5,"highlight_end":9}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:28:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m28\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Q4_1 = 3,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":687,"byte_end":691,"line_start":29,"line_end":29,"column_start":5,"column_end":9,"is_primary":true,"text":[{"text":"    Q5_0 = 6,","highlight_start":5,"highlight_end":9}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:29:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m29\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Q5_0 = 6,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":701,"byte_end":705,"line_start":30,"line_end":30,"column_start":5,"column_end":9,"is_primary":true,"text":[{"text":"    Q5_1 = 7,","highlight_start":5,"highlight_end":9}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:30:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m30\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Q5_1 = 7,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":715,"byte_end":719,"line_start":31,"line_end":31,"column_start":5,"column_end":9,"is_primary":true,"text":[{"text":"    Q8_0 = 8,","highlight_start":5,"highlight_end":9}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:31:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m31\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Q8_0 = 8,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":729,"byte_end":733,"line_start":32,"line_end":32,"column_start":5,"column_end":9,"is_primary":true,"text":[{"text":"    Q8_1 = 9,","highlight_start":5,"highlight_end":9}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:32:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m32\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Q8_1 = 9,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":743,"byte_end":746,"line_start":33,"line_end":33,"column_start":5,"column_end":8,"is_primary":true,"text":[{"text":"    Q2K = 10,","highlight_start":5,"highlight_end":8}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:33:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m33\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Q2K = 10,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":757,"byte_end":760,"line_start":34,"line_end":34,"column_start":5,"column_end":8,"is_primary":true,"text":[{"text":"    Q3K = 11,","highlight_start":5,"highlight_end":8}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:34:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m34\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Q3K = 11,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":771,"byte_end":774,"line_start":35,"line_end":35,"column_start":5,"column_end":8,"is_primary":true,"text":[{"text":"    Q4K = 12,","highlight_start":5,"highlight_end":8}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:35:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m35\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Q4K = 12,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":785,"byte_end":788,"line_start":36,"line_end":36,"column_start":5,"column_end":8,"is_primary":true,"text":[{"text":"    Q5K = 13,","highlight_start":5,"highlight_end":8}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:36:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m36\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Q5K = 13,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":799,"byte_end":802,"line_start":37,"line_end":37,"column_start":5,"column_end":8,"is_primary":true,"text":[{"text":"    Q6K = 14,","highlight_start":5,"highlight_end":8}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:37:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m37\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Q6K = 14,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":813,"byte_end":816,"line_start":38,"line_end":38,"column_start":5,"column_end":8,"is_primary":true,"text":[{"text":"    Q8K = 15,","highlight_start":5,"highlight_end":8}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:38:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m38\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Q8K = 15,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":827,"byte_end":833,"line_start":39,"line_end":39,"column_start":5,"column_end":11,"is_primary":true,"text":[{"text":"    Iq2Xxs = 16,","highlight_start":5,"highlight_end":11}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:39:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m39\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Iq2Xxs = 16,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":844,"byte_end":849,"line_start":40,"line_end":40,"column_start":5,"column_end":10,"is_primary":true,"text":[{"text":"    Iq2Xs = 17,","highlight_start":5,"highlight_end":10}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:40:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m40\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Iq2Xs = 17,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":860,"byte_end":866,"line_start":41,"line_end":41,"column_start":5,"column_end":11,"is_primary":true,"text":[{"text":"    Iq3Xxs = 18,","highlight_start":5,"highlight_end":11}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:41:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m41\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Iq3Xxs = 18,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":877,"byte_end":881,"line_start":42,"line_end":42,"column_start":5,"column_end":9,"is_primary":true,"text":[{"text":"    Iq1S = 19,","highlight_start":5,"highlight_end":9}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:42:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m42\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Iq1S = 19,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":892,"byte_end":897,"line_start":43,"line_end":43,"column_start":5,"column_end":10,"is_primary":true,"text":[{"text":"    Iq4Nl = 20,","highlight_start":5,"highlight_end":10}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:43:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m43\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Iq4Nl = 20,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":908,"byte_end":912,"line_start":44,"line_end":44,"column_start":5,"column_end":9,"is_primary":true,"text":[{"text":"    Iq3S = 21,","highlight_start":5,"highlight_end":9}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:44:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m44\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Iq3S = 21,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":923,"byte_end":927,"line_start":45,"line_end":45,"column_start":5,"column_end":9,"is_primary":true,"text":[{"text":"    Iq2S = 22,","highlight_start":5,"highlight_end":9}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:45:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m45\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Iq2S = 22,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":938,"byte_end":943,"line_start":46,"line_end":46,"column_start":5,"column_end":10,"is_primary":true,"text":[{"text":"    Iq4Xs = 23,","highlight_start":5,"highlight_end":10}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:46:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m46\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Iq4Xs = 23,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":954,"byte_end":956,"line_start":47,"line_end":47,"column_start":5,"column_end":7,"is_primary":true,"text":[{"text":"    I8 = 24,","highlight_start":5,"highlight_end":7}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:47:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m47\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     I8 = 24,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":967,"byte_end":970,"line_start":48,"line_end":48,"column_start":5,"column_end":8,"is_primary":true,"text":[{"text":"    I16 = 25,","highlight_start":5,"highlight_end":8}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:48:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m48\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     I16 = 25,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":981,"byte_end":984,"line_start":49,"line_end":49,"column_start":5,"column_end":8,"is_primary":true,"text":[{"text":"    I32 = 26,","highlight_start":5,"highlight_end":8}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:49:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m49\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     I32 = 26,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":995,"byte_end":998,"line_start":50,"line_end":50,"column_start":5,"column_end":8,"is_primary":true,"text":[{"text":"    I64 = 27,","highlight_start":5,"highlight_end":8}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:50:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m50\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     I64 = 27,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":1009,"byte_end":1012,"line_start":51,"line_end":51,"column_start":5,"column_end":8,"is_primary":true,"text":[{"text":"    F64 = 28,","highlight_start":5,"highlight_end":8}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:51:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m51\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     F64 = 28,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":1023,"byte_end":1027,"line_start":52,"line_end":52,"column_start":5,"column_end":9,"is_primary":true,"text":[{"text":"    Bf16 = 29,","highlight_start":5,"highlight_end":9}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n  \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:52:5\n   \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m52\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Bf16 = 29,\n   \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":2834,"byte_end":2839,"line_start":112,"line_end":112,"column_start":5,"column_end":10,"is_primary":true,"text":[{"text":"    Uint8(u8),","highlight_start":5,"highlight_end":10}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:112:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m112\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Uint8(u8),\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":2849,"byte_end":2853,"line_start":113,"line_end":113,"column_start":5,"column_end":9,"is_primary":true,"text":[{"text":"    Int8(i8),","highlight_start":5,"highlight_end":9}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:113:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m113\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Int8(i8),\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":2863,"byte_end":2869,"line_start":114,"line_end":114,"column_start":5,"column_end":11,"is_primary":true,"text":[{"text":"    Uint16(u16),","highlight_start":5,"highlight_end":11}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:114:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m114\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Uint16(u16),\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":2880,"byte_end":2885,"line_start":115,"line_end":115,"column_start":5,"column_end":10,"is_primary":true,"text":[{"text":"    Int16(i16),","highlight_start":5,"highlight_end":10}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:115:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m115\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Int16(i16),\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":2896,"byte_end":2902,"line_start":116,"line_end":116,"column_start":5,"column_end":11,"is_primary":true,"text":[{"text":"    Uint32(u32),","highlight_start":5,"highlight_end":11}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:116:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m116\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Uint32(u32),\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":2913,"byte_end":2918,"line_start":117,"line_end":117,"column_start":5,"column_end":10,"is_primary":true,"text":[{"text":"    Int32(i32),","highlight_start":5,"highlight_end":10}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:117:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m117\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Int32(i32),\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":2929,"byte_end":2936,"line_start":118,"line_end":118,"column_start":5,"column_end":12,"is_primary":true,"text":[{"text":"    Float32(f32),","highlight_start":5,"highlight_end":12}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:118:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m118\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Float32(f32),\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":2947,"byte_end":2953,"line_start":119,"line_end":119,"column_start":5,"column_end":11,"is_primary":true,"text":[{"text":"    Uint64(u64),","highlight_start":5,"highlight_end":11}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:119:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m119\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Uint64(u64),\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":2964,"byte_end":2969,"line_start":120,"line_end":120,"column_start":5,"column_end":10,"is_primary":true,"text":[{"text":"    Int64(i64),","highlight_start":5,"highlight_end":10}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:120:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m120\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Int64(i64),\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":2980,"byte_end":2987,"line_start":121,"line_end":121,"column_start":5,"column_end":12,"is_primary":true,"text":[{"text":"    Float64(f64),","highlight_start":5,"highlight_end":12}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:121:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m121\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Float64(f64),\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":2998,"byte_end":3002,"line_start":122,"line_end":122,"column_start":5,"column_end":9,"is_primary":true,"text":[{"text":"    Bool(bool),","highlight_start":5,"highlight_end":9}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:122:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m122\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Bool(bool),\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":3014,"byte_end":3020,"line_start":123,"line_end":123,"column_start":5,"column_end":11,"is_primary":true,"text":[{"text":"    String(String),","highlight_start":5,"highlight_end":11}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:123:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m123\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     String(String),\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a variant","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/gguf.rs","byte_start":3034,"byte_end":3039,"line_start":124,"line_end":124,"column_start":5,"column_end":10,"is_primary":true,"text":[{"text":"    Array(Vec<GgufValue>),","highlight_start":5,"highlight_end":10}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a variant\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/gguf.rs:124:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m124\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     Array(Vec<GgufValue>),\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a struct field","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/huggingface.rs","byte_start":3238,"byte_end":3270,"line_start":121,"line_end":121,"column_start":5,"column_end":37,"is_primary":true,"text":[{"text":"    pub scaling_type: Option<String>,","highlight_start":5,"highlight_end":37}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a struct field\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/huggingface.rs:121:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m121\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     pub scaling_type: Option<String>,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"missing documentation for a struct field","code":{"code":"missing_docs","explanation":null},"level":"warning","spans":[{"file_name":"crates/swiftllm-models/src/loaders/huggingface.rs","byte_start":3276,"byte_end":3299,"line_start":122,"line_end":122,"column_start":5,"column_end":28,"is_primary":true,"text":[{"text":"    pub factor: Option<f32>,","highlight_start":5,"highlight_end":28}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: missing documentation for a struct field\u001b[0m\n   \u001b[1m\u001b[94m--> \u001b[0mcrates/swiftllm-models/src/loaders/huggingface.rs:122:5\n    \u001b[1m\u001b[94m|\u001b[0m\n\u001b[1m\u001b[94m122\u001b[0m \u001b[1m\u001b[94m|\u001b[0m     pub factor: Option<f32>,\n    \u001b[1m\u001b[94m|\u001b[0m     \u001b[1m\u001b[33m^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"101 warnings emitted","code":null,"level":"warning","spans":[],"children":[],"rendered":"\u001b[1m\u001b[33mwarning\u001b[0m\u001b[1m: 101 warnings emitted\u001b[0m\n\n"}
